{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install unrar\n",
        "!pip install rarfile"
      ],
      "metadata": {
        "id": "FPY_k9gu6IBb"
      },
      "id": "FPY_k9gu6IBb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile\n",
        "\n",
        "rarfile.UNRAR_TOOL = \"/usr/bin/unrar\"\n",
        "!wget https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
        "\n",
        "rar_path = \"/content/dataset.rar\"  # Ruta del archivo RAR\n",
        "extract_path = \"dataset\"  # Carpeta de salida\n",
        "\n",
        "with rarfile.RarFile(rar_path) as rar_ref:\n",
        "    rar_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Archivo descomprimido correctamente.\")"
      ],
      "metadata": {
        "id": "9-g3gPHc6Hqa"
      },
      "id": "9-g3gPHc6Hqa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#algunas importaciones\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "pZPIYaYO6HeX"
      },
      "id": "pZPIYaYO6HeX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_origen = \"dataset/dataset/Training\"\n",
        "ruta_smoking = \"dataset/dataset/training/smoking\"\n",
        "ruta_notsmoking = \"dataset/dataset/training/notsmoking\"\n",
        "\n",
        "os.makedirs(ruta_smoking, exist_ok=True)\n",
        "os.makedirs(ruta_notsmoking, exist_ok=True)\n",
        "\n",
        "for archivo in os.listdir(ruta_origen):\n",
        "  if os.path.isfile(os.path.join(ruta_origen, archivo)):\n",
        "    if \"notsmoking\" not in archivo.lower() :\n",
        "            shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_smoking, archivo))\n",
        "    elif(True):\n",
        "            shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_notsmoking, archivo))\n",
        "\n",
        "\n",
        "datadir = \"/content/dataset/dataset/training\"\n",
        "imgsize = (224, 224)\n",
        "batchsize = (32)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                         batch_size=batchsize,class_mode='binary',subset='training')\n",
        "val_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                       batch_size=batchsize,class_mode='binary',subset='validation')"
      ],
      "metadata": {
        "id": "AYq7pRVM6plP"
      },
      "id": "AYq7pRVM6plP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb1296e",
      "metadata": {
        "id": "afb1296e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, regularizers\n",
        "\n",
        "# Modelo base Xception\n",
        "mnet = keras.applications.Xception(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "mnet.trainable = True\n",
        "for layer in mnet.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "\n",
        "    mnet,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.8),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=15,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=60,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "# Guardar el modelo entrenado\n",
        "model.save(\"modelo_xception.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}