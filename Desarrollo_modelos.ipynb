{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46de0bec-cfea-4325-9f1c-f337bf29765e",
      "metadata": {
        "id": "46de0bec-cfea-4325-9f1c-f337bf29765e"
      },
      "source": [
        "# Detector de imagenes (Fumadores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7acddd-9130-4d24-bc44-00dd823bdbbb",
      "metadata": {
        "id": "7e7acddd-9130-4d24-bc44-00dd823bdbbb"
      },
      "source": [
        "## Importación del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7683d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7683d6f",
        "outputId": "862e8a62-4ac7-4e90-8191-b0e1568adfe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ],
      "source": [
        "!apt-get install unrar\n",
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f040e1-2a7b-4720-9aef-8c071948ff8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f040e1-2a7b-4720-9aef-8c071948ff8c",
        "outputId": "60a83d7f-3a2d-4015-9682-1d11b162ed84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 20:23:31--  https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/refs/heads/main/recursos/dataset.rar [following]\n",
            "--2025-03-24 20:23:31--  https://raw.githubusercontent.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/refs/heads/main/recursos/dataset.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65567508 (63M) [application/octet-stream]\n",
            "Saving to: ‘dataset.rar’\n",
            "\n",
            "dataset.rar         100%[===================>]  62.53M   152MB/s    in 0.4s    \n",
            "\n",
            "2025-03-24 20:23:33 (152 MB/s) - ‘dataset.rar’ saved [65567508/65567508]\n",
            "\n",
            "Archivo descomprimido correctamente.\n"
          ]
        }
      ],
      "source": [
        "import rarfile\n",
        "\n",
        "rarfile.UNRAR_TOOL = \"/usr/bin/unrar\"\n",
        "!wget https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
        "\n",
        "rar_path = \"/content/dataset.rar\"  # Ruta del archivo RAR\n",
        "extract_path = \"dataset\"  # Carpeta de salida\n",
        "\n",
        "with rarfile.RarFile(rar_path) as rar_ref:\n",
        "    rar_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Archivo descomprimido correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8dd5744-c4c5-4783-868f-d974aea7d221",
      "metadata": {
        "id": "f8dd5744-c4c5-4783-868f-d974aea7d221"
      },
      "source": [
        "## Entrenamiento de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0440ec21",
      "metadata": {
        "id": "0440ec21"
      },
      "source": [
        "### SVC - Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96c30df",
      "metadata": {
        "id": "b96c30df"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cc9d82",
      "metadata": {
        "id": "91cc9d82"
      },
      "source": [
        "#### Tratamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225f1f92",
      "metadata": {
        "id": "225f1f92"
      },
      "outputs": [],
      "source": [
        "# Función para cargar las imagenes desde el folder y almacenarlas en forma de vector númerico, junto con otro array con su clasificación\n",
        "def svc_loadImages(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename)).convert(\"L\")\n",
        "        img = img.resize((250,250))\n",
        "        img_array = np.array(img).flatten()\n",
        "        images.append(img_array)\n",
        "        label = 0 if \"notsmoking\" in filename else 1 # Si el nombre de la imagen es 'notsmoking' colocar 0, caso contrario 1\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2afe626",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2afe626",
        "outputId": "c5139b05-7e50-4670-fc81-8bba5cf1ee9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento: 716\tPorcentaje: 63.93\n",
            "Datos de validación: 180\tPorcentaje: 16.07\n",
            "Datos de prueba: 224\t\tPorcentaje: 20.00\n"
          ]
        }
      ],
      "source": [
        "#Separacion imagenes train y test\n",
        "scv_Xtrain, svc_ytrain = svc_loadImages(\"dataset/dataset/Training\")\n",
        "svc_Xval, svc_yval = svc_loadImages(\"dataset/dataset/Validation\")\n",
        "svc_Xtest, svc_ytest = svc_loadImages(\"dataset/dataset/Testing\")\n",
        "\n",
        "print(f\"Datos de entrenamiento: {len(scv_Xtrain)}\\tPorcentaje: {(len(scv_Xtrain)*100/1120):.2f}\")\n",
        "print(f\"Datos de validación: {len(svc_Xval)}\\tPorcentaje: {(len(svc_Xval)*100/1120):.2f}\")\n",
        "print(f\"Datos de prueba: {len(svc_Xtest)}\\t\\tPorcentaje: {(len(svc_Xtest)*100/1120):.2f}\")\n",
        "\n",
        "\n",
        "#Escalado de imagenes con StandarScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scv_Xtrain_st = scaler.fit_transform(scv_Xtrain)\n",
        "scv_Xval_st = scaler.transform(svc_Xval)\n",
        "scv_Xtest_st = scaler.transform(svc_Xtest)\n",
        "\n",
        "scv_Xtrain[:2], scv_Xtrain_st[:2]\n",
        "\n",
        "\n",
        "#Reducir dimensionalidad con PCA a 90 componentes (componentes originales = 250)\n",
        "pca = PCA(n_components=90)\n",
        "\n",
        "scv_Xtrain_pca = pca.fit_transform(scv_Xtrain_st)\n",
        "scv_Xval_pca = pca.transform(scv_Xval_st)\n",
        "scv_Xtest_pca = pca.transform(scv_Xtest_st)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8752c327",
      "metadata": {
        "id": "8752c327"
      },
      "source": [
        "#### Entrenamiento del modelo svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1ce007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1ce007",
        "outputId": "25b5e7cf-b5f1-47e0-b247-258f96182b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntuación del mejor modelo: 0.77\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "svm = SVC(kernel=\"linear\", random_state=42)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "best_score = -np.inf\n",
        "best_model = None\n",
        "\n",
        "# Realizar validación cruzada\n",
        "for train_idx, val_idx in cv.split(scv_Xtrain_pca, svc_ytrain):\n",
        "    X_train_fold, X_val_fold = scv_Xtrain_pca[train_idx], scv_Xtrain_pca[val_idx]\n",
        "    y_train_fold, y_val_fold = svc_ytrain[train_idx], svc_ytrain[val_idx]\n",
        "\n",
        "\n",
        "    svm.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    score = svm.score(X_val_fold, y_val_fold)\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model = SVC(kernel=\"linear\", random_state=42)\n",
        "        best_model.fit(scv_Xtrain_pca, svc_ytrain)\n",
        "\n",
        "# Porcenaje final\n",
        "print(f\"Puntuación del mejor modelo: {best_score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64759500",
      "metadata": {
        "id": "64759500"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "40f80d26",
      "metadata": {
        "id": "40f80d26"
      },
      "source": [
        "#### Exportación de recursos (modelo, scaler, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5815dac5",
      "metadata": {
        "id": "5815dac5"
      },
      "outputs": [],
      "source": [
        "# Código"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a7ca25",
      "metadata": {
        "id": "09a7ca25"
      },
      "source": [
        "### MobileNetV2 (CNN) (keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6497b51",
      "metadata": {
        "id": "d6497b51"
      },
      "outputs": [],
      "source": [
        "#algunas importaciones\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5287521c",
      "metadata": {
        "id": "5287521c"
      },
      "source": [
        "Pre-procesamiento de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bae4b0",
      "metadata": {
        "id": "24bae4b0"
      },
      "outputs": [],
      "source": [
        "#en construcion#####\n",
        "datadir = \"/content/dataset/dataset/Training\"\n",
        "imgsize = (250,250)\n",
        "batchsize = (32)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(data_dir,target_size=img_size,\n",
        "                                         batch_size=batch_size,class_mode='binary',subset='training')\n",
        "val_data = datagen.flow_from_directory(data_dir,target_size=img_size,\n",
        "                                       batch_size=batch_size,class_mode='binary',subset='validation')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12191fb7",
      "metadata": {
        "id": "12191fb7"
      },
      "source": [
        "Instanciación del modelo (preentrenado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159d71b6",
      "metadata": {
        "id": "159d71b6"
      },
      "outputs": [],
      "source": [
        "mnet = keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}