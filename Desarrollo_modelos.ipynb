{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46de0bec-cfea-4325-9f1c-f337bf29765e",
      "metadata": {
        "id": "46de0bec-cfea-4325-9f1c-f337bf29765e"
      },
      "source": [
        "# Detector de imagenes (Fumadores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4c4bb1",
      "metadata": {
        "id": "4f4c4bb1"
      },
      "source": [
        "\"Remember Us\" presenta un innovador sistema de clasificación de imágenes basado en inteligencia artificial para detectar en tiempo real si una persona está fumando en áreas donde está prohibido, como gasolineras, fábricas con materiales inflamables o espacios públicos sensibles.\n",
        "\n",
        "**Objetivo:**\n",
        "Reducir el riesgo de incendios y accidentes en zonas de alto peligro mediante la implementación de inteligencia artificial para la detección automática de personas fumando en lugares prohibidos.\n",
        "\n",
        "**¿Porque es importante?**\n",
        "\n",
        "Según la NFPA, los incendios en gasolineras causan millones de dólares en pérdidas y ponen vidas en peligro. Los cigarrillos representan una de las principales causas de incendios en industrias.Con una solución automatizada, podemos prevenir tragedias antes de que ocurran.\n",
        "\n",
        "**Modelos utilizados:**\n",
        "\n",
        "|      Modelo                     | Precisión   |\n",
        "|---------------------------------|-------------|\n",
        "| YoloV8s                         | 90%         |\n",
        "| Xception                        | 82%         |\n",
        "| SVC - Sklearn                   | 77%         |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2962b4",
      "metadata": {},
      "source": [
        "## Precisión de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cedfd9ac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "modelos = [\"SVM\", \"Xception\", \"YOLOV8\"]\n",
        "precision = np.array([77, 82, 90])\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(modelos, precision, color=['blue', 'orange', 'green'])\n",
        "\n",
        "plt.xlabel(\"Modelos IA\")\n",
        "plt.ylabel(\"Precisión %\")\n",
        "plt.title(\"Precisión de Modelos de IA\")\n",
        "plt.ylim(70, 100)\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8dd5744-c4c5-4783-868f-d974aea7d221",
      "metadata": {
        "id": "f8dd5744-c4c5-4783-868f-d974aea7d221"
      },
      "source": [
        "## Entrenamiento de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0440ec21",
      "metadata": {
        "id": "0440ec21"
      },
      "source": [
        "### SVC - Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96c30df",
      "metadata": {
        "id": "b96c30df"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cc9d82",
      "metadata": {
        "id": "91cc9d82"
      },
      "source": [
        "#### Tratamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225f1f92",
      "metadata": {
        "id": "225f1f92"
      },
      "outputs": [],
      "source": [
        "# Función para cargar las imagenes desde el folder y almacenarlas en forma de vector númerico, junto con otro array con su clasificación\n",
        "def svc_loadImages(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename)).convert(\"L\")\n",
        "        img = img.resize((250,250))\n",
        "        img_array = np.array(img).flatten()\n",
        "        images.append(img_array)\n",
        "        label = 0 if \"notsmoking\" in filename else 1 # Si el nombre de la imagen es 'notsmoking' colocar 0, caso contrario 1\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2afe626",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2afe626",
        "outputId": "83d13c4b-ba81-4adf-fe73-219f25d59bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos de entrenamiento: 716\tPorcentaje: 63.93\n",
            "Datos de validación: 180\tPorcentaje: 16.07\n",
            "Datos de prueba: 224\t\tPorcentaje: 20.00\n"
          ]
        }
      ],
      "source": [
        "#Separacion imagenes train y test\n",
        "scv_Xtrain, svc_ytrain = svc_loadImages(\"recursos/dataset/Training\")\n",
        "svc_Xval, svc_yval = svc_loadImages(\"recursos/dataset/Validation\")\n",
        "svc_Xtest, svc_ytest = svc_loadImages(\"recursos/dataset/Testing\")\n",
        "\n",
        "print(f\"Datos de entrenamiento: {len(scv_Xtrain)}\\tPorcentaje: {(len(scv_Xtrain)*100/1120):.2f}\")\n",
        "print(f\"Datos de validación: {len(svc_Xval)}\\tPorcentaje: {(len(svc_Xval)*100/1120):.2f}\")\n",
        "print(f\"Datos de prueba: {len(svc_Xtest)}\\t\\tPorcentaje: {(len(svc_Xtest)*100/1120):.2f}\")\n",
        "\n",
        "\n",
        "#Escalado de imagenes con StandarScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scv_Xtrain_st = scaler.fit_transform(scv_Xtrain)\n",
        "scv_Xval_st = scaler.transform(svc_Xval)\n",
        "scv_Xtest_st = scaler.transform(svc_Xtest)\n",
        "\n",
        "scv_Xtrain[:2], scv_Xtrain_st[:2]\n",
        "\n",
        "\n",
        "#Reducir dimensionalidad con PCA a 90 componentes (componentes originales = 250)\n",
        "pca = PCA(n_components=90)\n",
        "\n",
        "scv_Xtrain_pca = pca.fit_transform(scv_Xtrain_st)\n",
        "scv_Xval_pca = pca.transform(scv_Xval_st)\n",
        "scv_Xtest_pca = pca.transform(scv_Xtest_st)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8752c327",
      "metadata": {
        "id": "8752c327"
      },
      "source": [
        "#### Entrenamiento del modelo svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1ce007",
      "metadata": {
        "id": "7c1ce007"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "svm = SVC(kernel=\"linear\", random_state=42)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "best_score = -np.inf\n",
        "best_model = None\n",
        "\n",
        "# Realizar validación cruzada\n",
        "for train_idx, val_idx in cv.split(scv_Xtrain_pca, svc_ytrain):\n",
        "    X_train_fold, X_val_fold = scv_Xtrain_pca[train_idx], scv_Xtrain_pca[val_idx]\n",
        "    y_train_fold, y_val_fold = svc_ytrain[train_idx], svc_ytrain[val_idx]\n",
        "\n",
        "\n",
        "    svm.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    score = svm.score(X_val_fold, y_val_fold)\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model = SVC(kernel=\"linear\", random_state=42)\n",
        "        best_model.fit(scv_Xtrain_pca, svc_ytrain)\n",
        "\n",
        "# Porcenaje final\n",
        "print(f\"Puntuación del mejor modelo: {best_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j6z04zr8uSiK",
      "metadata": {
        "id": "j6z04zr8uSiK"
      },
      "source": [
        "precision del 0.77"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a7ca25",
      "metadata": {
        "id": "09a7ca25"
      },
      "source": [
        "### MobileNetV2 (CNN) (keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6497b51",
      "metadata": {
        "id": "d6497b51"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5287521c",
      "metadata": {
        "id": "5287521c"
      },
      "source": [
        "Pre-procesamiento de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bae4b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24bae4b0",
        "outputId": "777c14f8-7065-430e-80e4-c8875d49ebd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 574 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "ruta_origen = \"dataset/dataset/Training\"\n",
        "ruta_smoking = \"dataset/dataset/training/smoking\"\n",
        "ruta_notsmoking = \"dataset/dataset/training/notsmoking\"\n",
        "\n",
        "os.makedirs(ruta_smoking, exist_ok=True)\n",
        "os.makedirs(ruta_notsmoking, exist_ok=True)\n",
        "\n",
        "for archivo in os.listdir(ruta_origen):\n",
        "  if os.path.isfile(os.path.join(ruta_origen, archivo)):\n",
        "    if \"notsmoking\" not in archivo.lower() :\n",
        "            shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_smoking, archivo))\n",
        "    elif(True):\n",
        "            shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_notsmoking, archivo))\n",
        "\n",
        "\n",
        "datadir = \"/content/dataset/dataset/training\"\n",
        "imgsize = (224, 224)\n",
        "batchsize = (32)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                         batch_size=batchsize,class_mode='binary',subset='training')\n",
        "val_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                       batch_size=batchsize,class_mode='binary',subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12191fb7",
      "metadata": {
        "id": "12191fb7"
      },
      "source": [
        "Instanciación del modelo (preentrenado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159d71b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "159d71b6",
        "outputId": "f50b2aa5-ac3f-4aad-e172-4c378d696b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 427ms/step - accuracy: 0.4607 - loss: 1.3647 - val_accuracy: 0.6268 - val_loss: 0.7300\n",
            "Epoch 2/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.5265 - loss: 1.2696 - val_accuracy: 0.6620 - val_loss: 0.7117\n",
            "Epoch 3/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - accuracy: 0.6285 - loss: 0.9654 - val_accuracy: 0.7042 - val_loss: 0.6884\n",
            "Epoch 4/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - accuracy: 0.5711 - loss: 1.1540 - val_accuracy: 0.7042 - val_loss: 0.6728\n",
            "Epoch 5/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.6053 - loss: 1.0211 - val_accuracy: 0.7324 - val_loss: 0.6569\n",
            "Epoch 6/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.6917 - loss: 0.8197 - val_accuracy: 0.7324 - val_loss: 0.6460\n",
            "Epoch 7/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.6643 - loss: 0.8676 - val_accuracy: 0.7183 - val_loss: 0.6278\n",
            "Epoch 8/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.6447 - loss: 0.8166 - val_accuracy: 0.7535 - val_loss: 0.6066\n",
            "Epoch 9/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - accuracy: 0.6818 - loss: 0.8453 - val_accuracy: 0.7535 - val_loss: 0.5956\n",
            "Epoch 10/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.7038 - loss: 0.8826 - val_accuracy: 0.7606 - val_loss: 0.5836\n",
            "Epoch 11/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.7176 - loss: 0.7569 - val_accuracy: 0.7465 - val_loss: 0.5760\n",
            "Epoch 12/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - accuracy: 0.6966 - loss: 0.7284 - val_accuracy: 0.7676 - val_loss: 0.5657\n",
            "Epoch 13/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.7144 - loss: 0.7131 - val_accuracy: 0.7606 - val_loss: 0.5539\n",
            "Epoch 14/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.6716 - loss: 0.7740 - val_accuracy: 0.7676 - val_loss: 0.5447\n",
            "Epoch 15/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - accuracy: 0.7471 - loss: 0.6854 - val_accuracy: 0.7676 - val_loss: 0.5392\n",
            "Epoch 16/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.7220 - loss: 0.7337 - val_accuracy: 0.7676 - val_loss: 0.5366\n",
            "Epoch 17/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.7467 - loss: 0.6518 - val_accuracy: 0.7676 - val_loss: 0.5338\n",
            "Epoch 18/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.7098 - loss: 0.6827 - val_accuracy: 0.7606 - val_loss: 0.5311\n",
            "Epoch 19/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - accuracy: 0.7611 - loss: 0.5563 - val_accuracy: 0.7606 - val_loss: 0.5276\n",
            "Epoch 20/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - accuracy: 0.7668 - loss: 0.5926 - val_accuracy: 0.7606 - val_loss: 0.5212\n",
            "Epoch 21/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.7809 - loss: 0.6524 - val_accuracy: 0.7817 - val_loss: 0.5074\n",
            "Epoch 22/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 222ms/step - accuracy: 0.7330 - loss: 0.6144 - val_accuracy: 0.7887 - val_loss: 0.5043\n",
            "Epoch 23/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - accuracy: 0.7752 - loss: 0.5498 - val_accuracy: 0.7958 - val_loss: 0.5046\n",
            "Epoch 24/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 233ms/step - accuracy: 0.7558 - loss: 0.6181 - val_accuracy: 0.8028 - val_loss: 0.5033\n",
            "Epoch 25/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.7864 - loss: 0.5228 - val_accuracy: 0.7958 - val_loss: 0.4945\n",
            "Epoch 26/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.7467 - loss: 0.6258 - val_accuracy: 0.7958 - val_loss: 0.4922\n",
            "Epoch 27/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 234ms/step - accuracy: 0.7494 - loss: 0.6144 - val_accuracy: 0.8169 - val_loss: 0.4816\n",
            "Epoch 28/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 223ms/step - accuracy: 0.7704 - loss: 0.5609 - val_accuracy: 0.8099 - val_loss: 0.4752\n",
            "Epoch 29/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.7633 - loss: 0.5476 - val_accuracy: 0.8099 - val_loss: 0.4653\n",
            "Epoch 30/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - accuracy: 0.7674 - loss: 0.5811 - val_accuracy: 0.8169 - val_loss: 0.4675\n",
            "Epoch 31/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - accuracy: 0.7713 - loss: 0.5225 - val_accuracy: 0.8099 - val_loss: 0.4682\n",
            "Epoch 32/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - accuracy: 0.8205 - loss: 0.5237 - val_accuracy: 0.8028 - val_loss: 0.4697\n",
            "Epoch 33/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 222ms/step - accuracy: 0.7988 - loss: 0.5236 - val_accuracy: 0.8028 - val_loss: 0.4728\n",
            "Epoch 34/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.8078 - loss: 0.5710 - val_accuracy: 0.8028 - val_loss: 0.4746\n",
            "Epoch 35/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8132 - loss: 0.4643 - val_accuracy: 0.8169 - val_loss: 0.4700\n",
            "Epoch 36/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 215ms/step - accuracy: 0.7879 - loss: 0.5207 - val_accuracy: 0.8169 - val_loss: 0.4668\n",
            "Epoch 37/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step - accuracy: 0.7826 - loss: 0.5403 - val_accuracy: 0.8169 - val_loss: 0.4696\n",
            "Epoch 38/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 223ms/step - accuracy: 0.8112 - loss: 0.5232 - val_accuracy: 0.8169 - val_loss: 0.4711\n",
            "Epoch 39/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - accuracy: 0.7830 - loss: 0.5432 - val_accuracy: 0.8239 - val_loss: 0.4743\n",
            "Epoch 40/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step - accuracy: 0.8223 - loss: 0.5161 - val_accuracy: 0.8239 - val_loss: 0.4816\n",
            "Epoch 41/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 227ms/step - accuracy: 0.8224 - loss: 0.4946 - val_accuracy: 0.8169 - val_loss: 0.4774\n",
            "Epoch 42/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8223 - loss: 0.4701 - val_accuracy: 0.8099 - val_loss: 0.4727\n",
            "Epoch 43/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - accuracy: 0.7982 - loss: 0.4913 - val_accuracy: 0.8239 - val_loss: 0.4680\n",
            "Epoch 44/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - accuracy: 0.8131 - loss: 0.5814 - val_accuracy: 0.8169 - val_loss: 0.4722\n",
            "Epoch 45/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - accuracy: 0.8135 - loss: 0.4871 - val_accuracy: 0.8099 - val_loss: 0.4769\n",
            "Epoch 46/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8475 - loss: 0.4381 - val_accuracy: 0.8099 - val_loss: 0.4736\n",
            "Epoch 47/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 223ms/step - accuracy: 0.8559 - loss: 0.4649 - val_accuracy: 0.8169 - val_loss: 0.4680\n",
            "Epoch 48/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 217ms/step - accuracy: 0.8169 - loss: 0.5046 - val_accuracy: 0.8169 - val_loss: 0.4612\n",
            "Epoch 49/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 248ms/step - accuracy: 0.8013 - loss: 0.4772 - val_accuracy: 0.8169 - val_loss: 0.4612\n",
            "Epoch 50/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - accuracy: 0.7914 - loss: 0.5096 - val_accuracy: 0.8239 - val_loss: 0.4612\n",
            "Epoch 51/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - accuracy: 0.8766 - loss: 0.3875 - val_accuracy: 0.8239 - val_loss: 0.4622\n",
            "Epoch 52/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 223ms/step - accuracy: 0.8070 - loss: 0.4962 - val_accuracy: 0.8239 - val_loss: 0.4640\n",
            "Epoch 53/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - accuracy: 0.8283 - loss: 0.4401 - val_accuracy: 0.8310 - val_loss: 0.4574\n",
            "Epoch 54/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 223ms/step - accuracy: 0.8004 - loss: 0.4884 - val_accuracy: 0.8380 - val_loss: 0.4560\n",
            "Epoch 55/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - accuracy: 0.8007 - loss: 0.5043 - val_accuracy: 0.8239 - val_loss: 0.4557\n",
            "Epoch 56/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step - accuracy: 0.8144 - loss: 0.4560 - val_accuracy: 0.8169 - val_loss: 0.4564\n",
            "Epoch 57/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - accuracy: 0.8204 - loss: 0.4379 - val_accuracy: 0.8169 - val_loss: 0.4540\n",
            "Epoch 58/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - accuracy: 0.8560 - loss: 0.3983 - val_accuracy: 0.8239 - val_loss: 0.4569\n",
            "Epoch 59/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - accuracy: 0.8038 - loss: 0.5196 - val_accuracy: 0.8239 - val_loss: 0.4594\n",
            "Epoch 60/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - accuracy: 0.8319 - loss: 0.4226 - val_accuracy: 0.8239 - val_loss: 0.4577\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, regularizers\n",
        "\n",
        "# Modelo base Xception\n",
        "mnet = keras.applications.Xception(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "mnet.trainable = True\n",
        "for layer in mnet.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "\n",
        "    mnet,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.8),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=15,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=60,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Mostrar el porcentaje de precisión final en validación\n",
        "final_accuracy = history.history['val_accuracy'][-1] * 100\n",
        "print(f\"Precisión final en validación: {final_accuracy:.2f}%\")\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "model.save(\"modelo_xception.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qm-NGs5MTXuX",
      "metadata": {
        "id": "Qm-NGs5MTXuX"
      },
      "source": [
        "## Yolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0kNkG5mETeOa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0kNkG5mETeOa",
        "outputId": "0c74ad5f-42cc-4a19-8b35-521029bb0195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 68.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.96 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/dataset/smokersYolo/data.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=250, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 15.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 65.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[250] must be multiple of max stride 32, updating to [256]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/smokersYolo/train/labels... 476 images, 0 backgrounds, 0 corrupt: 100%|██████████| 476/476 [00:00<00:00, 1654.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/smokersYolo/train/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/smokersYolo/valid/labels... 60 images, 0 backgrounds, 0 corrupt: 100%|██████████| 60/60 [00:00<00:00, 394.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/smokersYolo/valid/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 256 train, 256 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50     0.293G      1.861      2.328      1.797          6        256: 100%|██████████| 60/60 [00:08<00:00,  7.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.417       0.55      0.449      0.133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50     0.311G      1.703      1.893      1.707          5        256: 100%|██████████| 60/60 [00:05<00:00, 11.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.535      0.567      0.501      0.168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50     0.328G      1.744      1.882      1.743         12        256: 100%|██████████| 60/60 [00:06<00:00,  9.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.507      0.618      0.524      0.152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50     0.344G      1.705      1.826      1.697          6        256: 100%|██████████| 60/60 [00:05<00:00, 11.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60       0.48      0.583      0.517      0.174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50     0.361G       1.69      1.737       1.67          6        256: 100%|██████████| 60/60 [00:06<00:00,  9.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.638      0.646      0.677      0.232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50     0.379G      1.672      1.798      1.665          5        256: 100%|██████████| 60/60 [00:05<00:00, 11.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.582      0.604      0.609      0.201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50     0.395G      1.673      1.704      1.646          7        256: 100%|██████████| 60/60 [00:06<00:00,  9.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.514       0.67      0.577      0.232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50     0.412G       1.63      1.714      1.644          7        256: 100%|██████████| 60/60 [00:06<00:00,  8.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.406      0.683      0.529      0.195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      0.43G      1.613       1.68      1.633          6        256: 100%|██████████| 60/60 [00:06<00:00,  9.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.618      0.617      0.668      0.249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50     0.447G       1.58      1.597      1.587          9        256: 100%|██████████| 60/60 [00:05<00:00, 10.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.537       0.75      0.604      0.227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50     0.463G      1.577      1.553      1.594         10        256: 100%|██████████| 60/60 [00:05<00:00, 10.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.726      0.617      0.752      0.266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50      0.48G      1.544      1.566      1.587          6        256: 100%|██████████| 60/60 [00:05<00:00, 10.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.638       0.75      0.679      0.258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50     0.498G      1.579       1.52      1.604          7        256: 100%|██████████| 60/60 [00:05<00:00, 10.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.752      0.708      0.768      0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50     0.514G       1.57      1.554      1.587          8        256: 100%|██████████| 60/60 [00:05<00:00, 10.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60       0.56      0.717      0.559      0.208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50     0.531G      1.535      1.535      1.568          8        256: 100%|██████████| 60/60 [00:05<00:00, 10.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.656      0.683      0.726      0.267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50     0.549G      1.482      1.491      1.547          9        256: 100%|██████████| 60/60 [00:05<00:00, 10.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.618      0.728      0.761      0.288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50     0.566G      1.495      1.496      1.544         12        256: 100%|██████████| 60/60 [00:05<00:00, 10.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.758      0.783       0.79      0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50     0.582G      1.487      1.462      1.516         15        256: 100%|██████████| 60/60 [00:05<00:00, 10.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.678      0.683      0.664      0.239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50       0.6G      1.532      1.402      1.547         11        256: 100%|██████████| 60/60 [00:05<00:00, 10.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.779      0.706      0.828      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50     0.617G      1.452      1.349      1.506         10        256: 100%|██████████| 60/60 [00:05<00:00, 10.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.598      0.767      0.709      0.268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50     0.633G      1.446      1.375      1.521          8        256: 100%|██████████| 60/60 [00:05<00:00, 11.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.709      0.772      0.817      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      0.65G      1.476      1.321      1.523          6        256: 100%|██████████| 60/60 [00:05<00:00, 10.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  7.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.721      0.783      0.826      0.361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50     0.668G      1.426      1.329      1.486         10        256: 100%|██████████| 60/60 [00:05<00:00, 11.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.543      0.752      0.709      0.295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50     0.686G      1.385      1.322      1.458         10        256: 100%|██████████| 60/60 [00:06<00:00,  9.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.705      0.733      0.767      0.311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50     0.701G      1.412      1.266      1.474          9        256: 100%|██████████| 60/60 [00:05<00:00, 11.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.734        0.8      0.808      0.337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50     0.719G      1.426      1.274      1.486         13        256: 100%|██████████| 60/60 [00:06<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.779      0.764      0.831      0.368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50     0.736G      1.389      1.272      1.471         10        256: 100%|██████████| 60/60 [00:05<00:00, 11.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.717      0.817      0.824      0.325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50     0.754G      1.402      1.236      1.484          6        256: 100%|██████████| 60/60 [00:06<00:00,  9.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.705       0.75       0.79      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50      0.77G      1.367      1.217      1.441          8        256: 100%|██████████| 60/60 [00:05<00:00, 10.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.801      0.871      0.873      0.355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50     0.787G      1.364      1.195      1.447          8        256: 100%|██████████| 60/60 [00:06<00:00,  9.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.749      0.833      0.865      0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50     0.805G      1.317      1.193       1.43         11        256: 100%|██████████| 60/60 [00:05<00:00, 11.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.667      0.717      0.716       0.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50     0.822G      1.289      1.138      1.408          9        256: 100%|██████████| 60/60 [00:06<00:00,  9.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.827       0.85       0.91       0.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      33/50     0.838G      1.291      1.113      1.407         11        256: 100%|██████████| 60/60 [00:05<00:00, 11.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.779        0.8      0.826      0.329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      34/50     0.855G      1.283      1.084      1.411          7        256: 100%|██████████| 60/60 [00:06<00:00,  9.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.733      0.733      0.822      0.349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      35/50     0.873G      1.261      1.081      1.387          9        256: 100%|██████████| 60/60 [00:05<00:00, 11.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.784      0.683      0.808      0.368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      36/50     0.889G      1.227      1.072      1.379          7        256: 100%|██████████| 60/60 [00:06<00:00,  9.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.749      0.767       0.81      0.363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      37/50     0.906G      1.231      1.044      1.391         16        256: 100%|██████████| 60/60 [00:05<00:00, 11.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.835      0.845      0.887       0.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      38/50     0.924G      1.211      1.008      1.354         10        256: 100%|██████████| 60/60 [00:06<00:00,  9.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.822        0.8      0.876      0.359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      39/50     0.939G      1.246       1.05      1.386          5        256: 100%|██████████| 60/60 [00:05<00:00, 11.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.748       0.84      0.828      0.304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      40/50     0.957G      1.217      1.018      1.359         11        256: 100%|██████████| 60/60 [00:06<00:00,  9.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.751      0.767       0.83      0.329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      41/50     0.975G      1.184     0.9699      1.371          4        256: 100%|██████████| 60/60 [00:05<00:00, 10.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60       0.92       0.65      0.831      0.334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      42/50     0.992G      1.064     0.7964      1.277          4        256: 100%|██████████| 60/60 [00:06<00:00,  9.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  9.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.826       0.75      0.867      0.352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      43/50      1.01G      1.009     0.7322      1.232          4        256: 100%|██████████| 60/60 [00:05<00:00, 11.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.957      0.745      0.906       0.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      44/50      1.03G     0.9894     0.6952      1.208          4        256: 100%|██████████| 60/60 [00:06<00:00,  9.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.789        0.8      0.886      0.352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      45/50      1.04G     0.9801     0.6641      1.208          4        256: 100%|██████████| 60/60 [00:05<00:00, 11.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.867      0.783       0.87      0.343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      46/50      1.06G     0.9494     0.6687      1.204          4        256: 100%|██████████| 60/60 [00:06<00:00,  9.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.906       0.75      0.858      0.337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      47/50      1.08G     0.9201     0.6568      1.186          4        256: 100%|██████████| 60/60 [00:05<00:00, 11.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.905      0.767      0.905      0.344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      48/50      1.09G     0.8716     0.6133      1.138          4        256: 100%|██████████| 60/60 [00:06<00:00,  9.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 11.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.903      0.767      0.893      0.347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      49/50      1.11G     0.8842     0.6163      1.147          4        256: 100%|██████████| 60/60 [00:05<00:00, 11.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.925       0.75       0.89      0.339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      50/50      1.13G     0.8461     0.5915      1.144          4        256: 100%|██████████| 60/60 [00:06<00:00,  9.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00, 12.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.915      0.767      0.888      0.348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "50 epochs completed in 0.092 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.96 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         60         60      0.835      0.846      0.887       0.39\n",
            "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics 8.3.96 🚀 Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.30GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train/weights/best.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 5, 1344) (5.9 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxslim\n",
            "  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim) (24.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 191.9 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.9/142.9 kB 220.3 MB/s eta 0:00:00\n",
            "Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.8/280.8 MB 170.1 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 123.3 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 316.0 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx, humanfriendly, onnxslim, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-gpu-1.21.0 onnxslim-0.1.48\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 14.3s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim', 'onnxruntime-gpu']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 15.4s, saved as '/content/runs/detect/train/weights/best.onnx' (11.5 MB)\n",
            "\n",
            "Export complete (17.1s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=256  \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=256 data=/content/dataset/smokersYolo/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/runs/detect/train/weights/best.onnx'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Cargar un modelo preentrenado (base)\n",
        "model = YOLO(\"yolov8s.pt\")  # Puedes elegir entre diferentes tamaños: 'n', 's', 'm', 'l', 'x'\n",
        "\n",
        "# Entrenar el modelo con tu conjunto de datos\n",
        "model.train(\n",
        "    data=\"recursos/smokersYolo8/data.yaml\",  # Archivo YAML con la configuración del dataset\n",
        "    epochs=100,                      # Número de épocas\n",
        "    batch=16,                       # Tamaño del lote\n",
        "    imgsz=250,                      # Tamaño de la imagen\n",
        "    device=\"cuda\"                    # Usa \"cuda\" si tienes GPU\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19fc4d2",
      "metadata": {},
      "source": [
        "## **Conclusión:** \n",
        "\n",
        "\n",
        "\n",
        "La implementación de inteligencia artificial para la detección de personas fumando en áreas restringidas representa una solución innovadora y efectiva para mejorar la seguridad y el cumplimiento de normativas. Al automatizar la identificación de estas infracciones en tiempo real, se reduce la necesidad de monitoreo manual, se agiliza la respuesta ante riesgos y se previenen incidentes que podrían poner en peligro la salud y el bienestar de la comunidad.\n",
        "\n",
        "Este sistema no solo contribuye a la protección de espacios libres de humo, sino que también refuerza la concienciación sobre la importancia de respetar las regulaciones establecidas. Además, su capacidad de integración con sistemas de vigilancia y seguridad existentes lo convierte en una herramienta versátil y escalable.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
